{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Anything Goes Implementation"
      ],
      "metadata": {
        "id": "L7CoLbt6dvDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import io\n",
        "from math import log2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "import pickle"
      ],
      "metadata": {
        "id": "fQHSX_e1YPe0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encod_decod(data):\n",
        "  inputlen=10\n",
        "  vocab = set([c for a in data[0] for c in a])\n",
        "  vocab.add('<PAD>')\n",
        "  encoder = dict((c,i) for i,c in enumerate(vocab))\n",
        "  decoder = dict((i,c) for i,c in enumerate(vocab))\n",
        "  return inputlen,vocab,encoder,decoder"
      ],
      "metadata": {
        "id": "G1VnwOwtd2G6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inp_out(vocab,encoder,decoder):\n",
        "  X = []\n",
        "  y = []\n",
        "  inputlen = 10\n",
        "  for a in data[0]:\n",
        "      Xenc = [encoder['<PAD>']]*inputlen\n",
        "      for c in a:\n",
        "          X.append(Xenc.copy())\n",
        "          y.append(encoder[c])\n",
        "          Xenc.pop(0)\n",
        "          Xenc.append(encoder[c])\n",
        "      X.append(Xenc.copy())\n",
        "      y.append(encoder['<PAD>'])\n",
        "      \n",
        "  X = np.array(X)\n",
        "  y = to_categorical(y, num_classes=len(vocab))\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "ANa0pylLfGVF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_function(X,y):\n",
        "  X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.1, random_state = 42)\n",
        "  return X_train,X_dev,y_train,y_dev"
      ],
      "metadata": {
        "id": "dVNh8CrNgCTM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(vocab,inputlen,X_train,y_train,X_dev,y_dev):\n",
        "  emb_dim = 10\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(vocab), output_dim=emb_dim, input_length=inputlen))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(40))\n",
        "  model.add(Dense(len(vocab), activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  model.fit(X_train, y_train, batch_size=16384, epochs=50, validation_data=(X_dev, y_dev),verbose=2)\n",
        "  return model"
      ],
      "metadata": {
        "id": "W32s1rODgIS9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def anything_goes_model(char,model,encoder):\n",
        "  inputlen=10\n",
        "  Xout = [encoder['<PAD>']]*inputlen\n",
        "  Xout.pop(0)\n",
        "  Xout.append(encoder[char])\n",
        "  preds = model.predict(np.array([Xout]), verbose=0)\n",
        "  # print(\"Probabilities sum at each step: \",sum(preds[0]))\n",
        "\n",
        "  max_prob = max(preds[0])\n",
        "  # print(max_prob)\n",
        "  return max_prob\n",
        "\n"
      ],
      "metadata": {
        "id": "6mLufkewtWkY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_one(lang,model,encoder):\n",
        "  testfile = open(lang+'-test.txt', 'r')\n",
        "  max_history = 100\n",
        "  history = []\n",
        "  loss_anything_goes = 0\n",
        "  #loss_from_scratch = 0\n",
        "  count = 0\n",
        "  while True:\n",
        "    c = testfile.read(1)\n",
        "    #print(c)\n",
        "    if not c:\n",
        "      break\n",
        "    count += 1\n",
        "    loss_anything_goes -= log2(anything_goes_model(c, model,encoder))\n",
        "    #loss_from_scratch -= log2(from_scratch_model(lang, c, history))\n",
        "    if len(history) == max_history:\n",
        "      history.pop(0)\n",
        "    history.append(c)\n",
        "    #print(loss_anything_goes)\n",
        "  return [loss_anything_goes/count]"
      ],
      "metadata": {
        "id": "tEML9ubfim8g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kwere Execution"
      ],
      "metadata": {
        "id": "Wp-bnw6AJHFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=open(\"cwe-train.txt\",'r',encoding = \"UTF-8\").readlines()\n",
        "inputlen,vocab,encoder,decoder=encod_decod(data)\n",
        "X,y=inp_out(vocab,encoder,decoder)\n",
        "X_train, X_dev, y_train, y_dev=split_function(X,y)\n",
        "model=model(vocab,inputlen,X_train,y_train,X_dev,y_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yoie9YGXFzFQ",
        "outputId": "2711c393-96de-4037-e61b-97ee40832cd6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 10, 10)            330       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 40)                4040      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 33)                1353      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,723\n",
            "Trainable params: 5,723\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "67/67 - 1s - loss: 2.7144 - accuracy: 0.4584 - val_loss: 2.0019 - val_accuracy: 0.5008 - 969ms/epoch - 14ms/step\n",
            "Epoch 2/50\n",
            "67/67 - 0s - loss: 1.8133 - accuracy: 0.4999 - val_loss: 1.6250 - val_accuracy: 0.5008 - 454ms/epoch - 7ms/step\n",
            "Epoch 3/50\n",
            "67/67 - 0s - loss: 1.5339 - accuracy: 0.5582 - val_loss: 1.4790 - val_accuracy: 0.5728 - 373ms/epoch - 6ms/step\n",
            "Epoch 4/50\n",
            "67/67 - 0s - loss: 1.4658 - accuracy: 0.5723 - val_loss: 1.4548 - val_accuracy: 0.5728 - 380ms/epoch - 6ms/step\n",
            "Epoch 5/50\n",
            "67/67 - 0s - loss: 1.4525 - accuracy: 0.5723 - val_loss: 1.4481 - val_accuracy: 0.5728 - 421ms/epoch - 6ms/step\n",
            "Epoch 6/50\n",
            "67/67 - 0s - loss: 1.4481 - accuracy: 0.5723 - val_loss: 1.4453 - val_accuracy: 0.5728 - 414ms/epoch - 6ms/step\n",
            "Epoch 7/50\n",
            "67/67 - 0s - loss: 1.4461 - accuracy: 0.5721 - val_loss: 1.4439 - val_accuracy: 0.5728 - 392ms/epoch - 6ms/step\n",
            "Epoch 8/50\n",
            "67/67 - 0s - loss: 1.4450 - accuracy: 0.5723 - val_loss: 1.4432 - val_accuracy: 0.5728 - 412ms/epoch - 6ms/step\n",
            "Epoch 9/50\n",
            "67/67 - 0s - loss: 1.4444 - accuracy: 0.5723 - val_loss: 1.4426 - val_accuracy: 0.5728 - 361ms/epoch - 5ms/step\n",
            "Epoch 10/50\n",
            "67/67 - 0s - loss: 1.4440 - accuracy: 0.5720 - val_loss: 1.4422 - val_accuracy: 0.5728 - 410ms/epoch - 6ms/step\n",
            "Epoch 11/50\n",
            "67/67 - 0s - loss: 1.4436 - accuracy: 0.5721 - val_loss: 1.4421 - val_accuracy: 0.5728 - 376ms/epoch - 6ms/step\n",
            "Epoch 12/50\n",
            "67/67 - 0s - loss: 1.4435 - accuracy: 0.5720 - val_loss: 1.4418 - val_accuracy: 0.5728 - 371ms/epoch - 6ms/step\n",
            "Epoch 13/50\n",
            "67/67 - 0s - loss: 1.4433 - accuracy: 0.5722 - val_loss: 1.4417 - val_accuracy: 0.5728 - 410ms/epoch - 6ms/step\n",
            "Epoch 14/50\n",
            "67/67 - 0s - loss: 1.4432 - accuracy: 0.5719 - val_loss: 1.4417 - val_accuracy: 0.5728 - 404ms/epoch - 6ms/step\n",
            "Epoch 15/50\n",
            "67/67 - 0s - loss: 1.4431 - accuracy: 0.5718 - val_loss: 1.4415 - val_accuracy: 0.5728 - 376ms/epoch - 6ms/step\n",
            "Epoch 16/50\n",
            "67/67 - 0s - loss: 1.4430 - accuracy: 0.5720 - val_loss: 1.4414 - val_accuracy: 0.5728 - 431ms/epoch - 6ms/step\n",
            "Epoch 17/50\n",
            "67/67 - 0s - loss: 1.4429 - accuracy: 0.5719 - val_loss: 1.4413 - val_accuracy: 0.5728 - 406ms/epoch - 6ms/step\n",
            "Epoch 18/50\n",
            "67/67 - 0s - loss: 1.4429 - accuracy: 0.5720 - val_loss: 1.4413 - val_accuracy: 0.5728 - 439ms/epoch - 7ms/step\n",
            "Epoch 19/50\n",
            "67/67 - 0s - loss: 1.4428 - accuracy: 0.5721 - val_loss: 1.4413 - val_accuracy: 0.5728 - 417ms/epoch - 6ms/step\n",
            "Epoch 20/50\n",
            "67/67 - 0s - loss: 1.4428 - accuracy: 0.5717 - val_loss: 1.4413 - val_accuracy: 0.5728 - 382ms/epoch - 6ms/step\n",
            "Epoch 21/50\n",
            "67/67 - 0s - loss: 1.4428 - accuracy: 0.5722 - val_loss: 1.4413 - val_accuracy: 0.5728 - 400ms/epoch - 6ms/step\n",
            "Epoch 22/50\n",
            "67/67 - 0s - loss: 1.4428 - accuracy: 0.5718 - val_loss: 1.4413 - val_accuracy: 0.5728 - 367ms/epoch - 5ms/step\n",
            "Epoch 23/50\n",
            "67/67 - 0s - loss: 1.4427 - accuracy: 0.5720 - val_loss: 1.4412 - val_accuracy: 0.5713 - 385ms/epoch - 6ms/step\n",
            "Epoch 24/50\n",
            "67/67 - 0s - loss: 1.4427 - accuracy: 0.5721 - val_loss: 1.4411 - val_accuracy: 0.5728 - 352ms/epoch - 5ms/step\n",
            "Epoch 25/50\n",
            "67/67 - 0s - loss: 1.4427 - accuracy: 0.5718 - val_loss: 1.4412 - val_accuracy: 0.5728 - 424ms/epoch - 6ms/step\n",
            "Epoch 26/50\n",
            "67/67 - 0s - loss: 1.4427 - accuracy: 0.5721 - val_loss: 1.4412 - val_accuracy: 0.5713 - 378ms/epoch - 6ms/step\n",
            "Epoch 27/50\n",
            "67/67 - 0s - loss: 1.4427 - accuracy: 0.5716 - val_loss: 1.4412 - val_accuracy: 0.5728 - 418ms/epoch - 6ms/step\n",
            "Epoch 28/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5721 - val_loss: 1.4410 - val_accuracy: 0.5728 - 381ms/epoch - 6ms/step\n",
            "Epoch 29/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5715 - val_loss: 1.4412 - val_accuracy: 0.5728 - 443ms/epoch - 7ms/step\n",
            "Epoch 30/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5720 - val_loss: 1.4410 - val_accuracy: 0.5728 - 470ms/epoch - 7ms/step\n",
            "Epoch 31/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5720 - val_loss: 1.4411 - val_accuracy: 0.5713 - 388ms/epoch - 6ms/step\n",
            "Epoch 32/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5716 - val_loss: 1.4410 - val_accuracy: 0.5728 - 392ms/epoch - 6ms/step\n",
            "Epoch 33/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5717 - val_loss: 1.4412 - val_accuracy: 0.5728 - 380ms/epoch - 6ms/step\n",
            "Epoch 34/50\n",
            "67/67 - 0s - loss: 1.4427 - accuracy: 0.5718 - val_loss: 1.4410 - val_accuracy: 0.5728 - 387ms/epoch - 6ms/step\n",
            "Epoch 35/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5719 - val_loss: 1.4412 - val_accuracy: 0.5728 - 417ms/epoch - 6ms/step\n",
            "Epoch 36/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5717 - val_loss: 1.4410 - val_accuracy: 0.5728 - 374ms/epoch - 6ms/step\n",
            "Epoch 37/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5720 - val_loss: 1.4410 - val_accuracy: 0.5728 - 369ms/epoch - 6ms/step\n",
            "Epoch 38/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5717 - val_loss: 1.4410 - val_accuracy: 0.5728 - 409ms/epoch - 6ms/step\n",
            "Epoch 39/50\n",
            "67/67 - 0s - loss: 1.4425 - accuracy: 0.5718 - val_loss: 1.4411 - val_accuracy: 0.5728 - 407ms/epoch - 6ms/step\n",
            "Epoch 40/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5721 - val_loss: 1.4410 - val_accuracy: 0.5728 - 389ms/epoch - 6ms/step\n",
            "Epoch 41/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5720 - val_loss: 1.4411 - val_accuracy: 0.5728 - 381ms/epoch - 6ms/step\n",
            "Epoch 42/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5722 - val_loss: 1.4410 - val_accuracy: 0.5713 - 372ms/epoch - 6ms/step\n",
            "Epoch 43/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5718 - val_loss: 1.4411 - val_accuracy: 0.5728 - 390ms/epoch - 6ms/step\n",
            "Epoch 44/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5715 - val_loss: 1.4410 - val_accuracy: 0.5728 - 363ms/epoch - 5ms/step\n",
            "Epoch 45/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5718 - val_loss: 1.4410 - val_accuracy: 0.5713 - 374ms/epoch - 6ms/step\n",
            "Epoch 46/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5719 - val_loss: 1.4411 - val_accuracy: 0.5728 - 386ms/epoch - 6ms/step\n",
            "Epoch 47/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5718 - val_loss: 1.4410 - val_accuracy: 0.5713 - 406ms/epoch - 6ms/step\n",
            "Epoch 48/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5719 - val_loss: 1.4410 - val_accuracy: 0.5728 - 398ms/epoch - 6ms/step\n",
            "Epoch 49/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5720 - val_loss: 1.4411 - val_accuracy: 0.5728 - 362ms/epoch - 5ms/step\n",
            "Epoch 50/50\n",
            "67/67 - 0s - loss: 1.4426 - accuracy: 0.5717 - val_loss: 1.4410 - val_accuracy: 0.5728 - 374ms/epoch - 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwere_results=evaluate_one('cwe',model,encoder)"
      ],
      "metadata": {
        "id": "--Gh8taeFzNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model"
      ],
      "metadata": {
        "id": "hvaD7nhVJh2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/kwere_results_final', 'wb') as file:\n",
        "  pickle.dump(kwere_results, file)"
      ],
      "metadata": {
        "id": "hpq1xkR-uZpX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "ITrKLkJYJlqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/kwere_results_final','rb') as file:\n",
        "    kwere_results = pickle.load(file)"
      ],
      "metadata": {
        "id": "px9XHbIXJk7e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Entropy Loss"
      ],
      "metadata": {
        "id": "hIur-fj2K80f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CWE Cross Entropy Loss: \",kwere_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYW7kkTuk29h",
        "outputId": "37cab8bb-3c21-4221-e9ea-2d2b9ba7ac62"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWE Cross Entropy Loss:  [3.5078298424387603e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Swahili Execution"
      ],
      "metadata": {
        "id": "1-Xcdt0tLHKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=open(\"sw-train.txt\",'r',encoding = \"UTF-8\").readlines()\n",
        "inputlen,vocab,encoder,decoder=encod_decod(data)\n",
        "X,y=inp_out(vocab,encoder,decoder)\n",
        "X_train, X_dev, y_train, y_dev=split_function(X,y)\n",
        "sw_model=model(vocab,inputlen,X_train,y_train,X_dev,y_dev)"
      ],
      "metadata": {
        "id": "C8n105i12DEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swahili_results=evaluate_one('sw',sw_model,encoder)"
      ],
      "metadata": {
        "id": "nvLnpjfMNi1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model"
      ],
      "metadata": {
        "id": "XQdZlwS0S6R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/swahili_results_final', 'wb') as file:\n",
        "  pickle.dump(swahili_results, file)"
      ],
      "metadata": {
        "id": "E6OizMNBQphT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "hNF2iG3KS8HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/swahili_results_final','rb') as file:\n",
        "    swahili_results = pickle.load(file)"
      ],
      "metadata": {
        "id": "G4kDuEI3QsNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Entropy Loss"
      ],
      "metadata": {
        "id": "WDgGPv-eTA2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CWE Cross Entropy Loss: \",swahili_results)"
      ],
      "metadata": {
        "id": "Zl4JsA7GQuN_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L7CoLbt6dvDF"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}