{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Anything Goes Implementation"
      ],
      "metadata": {
        "id": "lBHKGo8Mz8oG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import io\n",
        "from math import log2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "import pickle"
      ],
      "metadata": {
        "id": "BBcULG64SvuW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_data(path):\n",
        "  data=open(path,'r',encoding = \"UTF-8\").readlines()\n",
        "  chars = sorted(list(set(data[0])))\n",
        "  print(\"Total disctinct chars:\", len(chars))\n",
        "  return data,chars"
      ],
      "metadata": {
        "id": "FtJSCRaLSwHw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inp_out_structure(data):\n",
        "  maxlen = 30\n",
        "  step = 2\n",
        "  input = []\n",
        "  output = []\n",
        "  for i in range(0, len(data[0]) - maxlen, step):\n",
        "      input.append(data[0][i : i + maxlen])\n",
        "      output.append(data[0][i + maxlen])\n",
        "  print(\"Length of sequences:\", len(input))\n",
        "  return input,output,maxlen"
      ],
      "metadata": {
        "id": "wiVsyFjpS4Kn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_input_output_seq(input,output):\n",
        "  print(\"Input characters along with their original next character\\n\")\n",
        "  for i in range(5):\n",
        "    print( input[i],\" \", output[i])"
      ],
      "metadata": {
        "id": "ynq42S-aS7si"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encod_decod(data):\n",
        "  char_indices={}\n",
        "  indices_char={}\n",
        "  for i,c in enumerate(chars):\n",
        "    indices_char[i]=c\n",
        "  for i,c in enumerate(chars):\n",
        "    char_indices[c]=i\n",
        "  return char_indices,indices_char"
      ],
      "metadata": {
        "id": "h4Qv73EWS-de"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inp_out(chars,char_indices,output,maxlen):\n",
        "  x = np.zeros((len(input), maxlen, len(chars)), dtype=np.bool)\n",
        "  y = np.zeros((len(input), len(chars)), dtype=np.bool)\n",
        "  for i, s in enumerate(input):\n",
        "      for t, char in enumerate(s):\n",
        "          x[i, t, char_indices[char]] = 1\n",
        "      y[i, char_indices[output[i]]] = 1\n",
        "  return x,y\n"
      ],
      "metadata": {
        "id": "E7_iKfURTHFI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_Model(maxlen,chars,x,y):\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=(maxlen, len(chars))),\n",
        "          layers.LSTM(128),\n",
        "          layers.Dense(len(chars), activation=\"softmax\"),\n",
        "      ]\n",
        "  )\n",
        "  optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
        "  model.fit(x, y, batch_size=128, epochs=1)\n",
        "  return model"
      ],
      "metadata": {
        "id": "BRSZvzi6TKS9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def anything_goes_model(sentence,c,char_indices,chars,model,maxlen):\n",
        "  #print(\"sentence collection: \",sentence[-1])\n",
        "  x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "  for t, char in enumerate(sentence[:-1]):             #sentence is the fixed history of 30 characters from training set\n",
        "                                                       #excluding the last character from the sentence because that character is the character passed from test set which i am passing as a history.   \n",
        "      x_pred[0, t, char_indices[char]] = 1.0\n",
        "  preds = model.predict(x_pred, verbose=0)[0]\n",
        "  #print(preds[char_indices[sentence[-1]]])\n",
        "  return preds[char_indices[c]]       #chosing the probability of the word passed from test set"
      ],
      "metadata": {
        "id": "4F1b17zvTQSN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_one(lang,model,char_indices,chars,maxlen):\n",
        "  testfile = open(lang+'-test.txt', 'r')\n",
        "  max_history = 30\n",
        "  history=''\n",
        "  loss_anything_goes = 0\n",
        "  count = 0\n",
        "  while True:\n",
        "    c = testfile.read(1)\n",
        "    if not c:\n",
        "      break\n",
        "    count += 1\n",
        "    history+=(c)              #Appending the character to history string to maintain a history of max 30 characters\n",
        "    #print(history)\n",
        "    loss_anything_goes -= log2(anything_goes_model(history,c,char_indices,chars,model,maxlen))\n",
        "    if len(history) == max_history:        #Upon reaching max history limit I would skip the first character\n",
        "      history=history[1:]\n",
        "    #history+=c\n",
        "    #print(loss_anything_goes/count)\n",
        "  return loss_anything_goes/count"
      ],
      "metadata": {
        "id": "gkQL64BHhcAC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kwere Execution"
      ],
      "metadata": {
        "id": "a1TrSUZK08S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/Colab Notebooks/DeepLearning/cwe-train.txt\"\n",
        "data,chars=input_data(path)\n",
        "input,output,maxlen=inp_out_structure(data)\n",
        "show_input_output_seq(input,output)\n",
        "char_indices,indices_char=encod_decod(data)\n",
        "x,y=inp_out(chars,char_indices,output,maxlen)\n",
        "model=LSTM_Model(maxlen,chars,x,y)"
      ],
      "metadata": {
        "id": "ltbbuxT2l9Q9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df19d907-87f8-4293-d6b0-5b5f5bbf1dd8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total disctinct chars: 32\n",
            "Length of sequences: 301701\n",
            "Input characters along with their original next character\n",
            "\n",
            "chikale vinogile fana viya wan   h\n",
            "ikale vinogile fana viya wanhu    \n",
            "ale vinogile fana viya wanhu w   o\n",
            "e vinogile fana viya wanhu woc   h\n",
            "vinogile fana viya wanhu wochi   k\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2358/2358 [==============================] - 17s 6ms/step - loss: 1.4785 - accuracy: 0.5384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwere_results=evaluate_one('cwe',model,char_indices,chars,maxlen)"
      ],
      "metadata": {
        "id": "8Vtw_YblWeq5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwere_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPArZwD9t0RV",
        "outputId": "aa75537a-d9d9-4c2d-c89b-4520e28274c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.585875142796728"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/kwere_results', 'wb') as file:\n",
        "  pickle.dump(kwere_results, file)"
      ],
      "metadata": {
        "id": "3jsNBBjrX5gu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/kwere_results','rb') as file:\n",
        "    kwere_results = pickle.load(file)"
      ],
      "metadata": {
        "id": "UUdExCB5iyQQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Swahili Execution"
      ],
      "metadata": {
        "id": "DDFuIm221BVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/Colab Notebooks/DeepLearning/sw-train.txt\"\n",
        "data,chars=input_data(path)\n",
        "input,output,maxlen=inp_out_structure(data)\n",
        "show_input_output_seq(input,output)\n",
        "char_indices,indices_char=encod_decod(data)\n",
        "x,y=inp_out(chars,char_indices,output,maxlen)\n",
        "model=LSTM_Model(maxlen,chars,x,y)"
      ],
      "metadata": {
        "id": "P_iqolEbzN7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swahili_results=evaluate_one('sw',model,char_indices,chars,maxlen)"
      ],
      "metadata": {
        "id": "KqSaE3We19gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/swahili_results', 'wb') as file:\n",
        "  pickle.dump(swahili_results, file)"
      ],
      "metadata": {
        "id": "xma_rBjn2EWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/swahili_results','rb') as file:\n",
        "    swahili_results = pickle.load(file)"
      ],
      "metadata": {
        "id": "31Kt9Rxs2E_C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}