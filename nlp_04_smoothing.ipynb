{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aqeel-12/Bantu-Language-Modeling/blob/main/nlp_04_smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFeg-Zqpe6AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3c9c7a-fb7a-4aba-ae07-91df0043b474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach of the Code**"
      ],
      "metadata": {
        "id": "_9XMVqUckds1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "======================================================================= 1 Loading   \n",
        "1) Load train dataset  \n",
        "\n",
        "======================================================================= 2 Cleaning  \n",
        "2) Prepare the useful characters: ASCII_Chars  \n",
        "3) Clean dataset:  \n",
        "  - Remove punctuation characters  \n",
        "  - List of all the characters without losing the order of the characters  \n",
        "\n",
        "======================================================================= 3 Training     \n",
        "4) Find the ngrams & ngram_nextCharacters of these characters  \n",
        "5) Find ngrams count & ngram_nextCharacters count and store them  \n",
        "\n",
        "======================================================================= 4 Probability  \n",
        "6) Find the probability of ngram & nextChar  \n",
        "\n",
        "======================================================================= 5 Evaluating  \n",
        "8) For each given history & nextChar,   \n",
        "  - get the probability of history(ngram) and nextChar  \n",
        "  - apply -log2 on probability  \n",
        "  - summation of all these gives result as log2loss.  "
      ],
      "metadata": {
        "id": "z_BGsYX7WJ5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining Language Model**"
      ],
      "metadata": {
        "id": "MCvUGtnNgmh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "0JDOhM3_fNDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = list(\"ngrams_nextChars are stored successfully\")\n",
        "n=3\n",
        "ngram = 3*[\"<START>\"] # ('<START>', '<START>', '<START>')\n",
        "for char in L:  \n",
        "  totalLoss += -log2(ngrams_nextChars[('<START>', '<START>', '<START>'), 'n')]/ngrams[('<START>', '<START>', '<START>')])\n",
        "  ngram = ngram[1:]+[char]\n",
        "return totalLoss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtRXMX6aAvp5",
        "outputId": "084db3da-c6a9-4bb7-cb53-f7f5310c68f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<START>', '<START>', '<START>', 'n', 'g', 'r', 'a', 'm', 's', '_', 'n', 'e', 'x', 't', 'C', 'h', 'a', 'r', 's', ' ', 'a', 'r', 'e', ' ', 's', 't', 'o', 'r', 'e', 'd', ' ', 's', 'u', 'c', 'c', 'e', 's', 's', 'f', 'u', 'l', 'l', 'y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ngram, char\n",
        "#ngram = tuple(ngram[1:]+[char])\n",
        "#char = \"g\"\n",
        "ngram, char\n",
        "totalLoss += -log2(prob((('<START>', '<START>', 'n'), 'g'))/ prob(('<START>', '<START>', 'n')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhcqJ_4uCDJ8",
        "outputId": "f0334a11-68fc-4dc7-adaa-213a2991b5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('<START>', '<START>', 'n'), 'g')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DictionaryFunctions:\n",
        "  def __init__(self) -> None:\n",
        "    pass\n",
        "  def addVal_to_dictKey(self, D, k, val=1): # Inputs: Dictionary, Key, Value; Ouput: Dictionary (Updated)\n",
        "    if k in D:\n",
        "      if type(val)==int:\n",
        "        D[k] += val\n",
        "      elif (type(val)==str):\n",
        "        D[k].append(val)\n",
        "    else:\n",
        "      if type(val)==int:\n",
        "        D[k] = val\n",
        "      elif (type(val)==str):\n",
        "        D[k] = [val]\n",
        "    return D\n",
        "\n",
        "  def find_probs_of_dict(self, D):\n",
        "    total = 0\n",
        "    for key in D.keys():\n",
        "      total += D[key]\n",
        "    for key in D.keys():\n",
        "      D[key] /= total\n",
        "    return D \n",
        "\n",
        "  def get_dict_from_list(self, L):\n",
        "    D = {}\n",
        "    for char in L:\n",
        "      if char in D:\n",
        "        D[char] += 1\n",
        "      else:\n",
        "        D[char] = 1\n",
        "    return D\n",
        "\n",
        "  def max_of_dict(self, D):  \n",
        "    maxProb = 0\n",
        "    maxKey = ''\n",
        "    for key, probVal in D.items():\n",
        "      if probVal>maxProb:\n",
        "        maxProb = probVal\n",
        "        maxKey = key\n",
        "    return (maxKey, maxProb)"
      ],
      "metadata": {
        "id": "TsMUF__fmwzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Language_Model:\n",
        "  def __init__(self, n, lang=\"\") -> None:\n",
        "    self.n = n\n",
        "    self.lang = lang\n",
        "    self.DF = DictionaryFunctions()\n",
        "    self.ASCII_Chars = ' !\"\\'(),-.0123456789:;?abcdefghijklmnopqrstuvwxyz'\n",
        "    self.sentence_EndChars = '.!?'\n",
        "    self.ngrams = {}\n",
        "    self.ngrams_nextChars = {}\n",
        "    self._ngrams_List = []\n",
        "    self._ngrams_nextChars_List = []\n",
        "    self._ngrams_possChars = {}\n",
        "    self.startPad = ['<START>']\n",
        "    self.endPad = ['<END>']\n",
        "    self._ngrams_Available = []\n",
        "    self._ngrams_nextChars_Available = []\n",
        "    self._ngrams_notAvailable = []\n",
        "    self._ngrams_nextChars_notAvailable = []\n",
        "    self.train_chars_len = None\n",
        "    self.train_char_prob = None\n",
        "  \n",
        "  def _char_prob(self, chars_List):\n",
        "    print(chars_List)\n",
        "    char_prob = self.DF.get_dict_from_list(chars_List)\n",
        "    char_prob = self.DF.find_probs_of_dict(char_prob)\n",
        "    return char_prob\n",
        "\n",
        "  def _get_ngrams(self, text):\n",
        "    n = self.n\n",
        "    chars_tokens = (n)*self.startPad + text + (n)*self.endPad\n",
        "    ngrams_nextChars = [(tuple(chars_tokens[i:i+n]),chars_tokens[i+n]) for i in range(len(chars_tokens)-n)]\n",
        "    return ngrams_nextChars\n",
        "\n",
        "  def clean_data(self, dataset: str) -> list:  \n",
        "    ASCII_Chars = self.ASCII_Chars\n",
        "    all_characters_in_data = re.findall(r\"[%s]\"%ASCII_Chars, dataset)\n",
        "    # data_clean = \"\".join(all_characters_in_data)\n",
        "    self.train_chars_len = len(all_characters_in_data)\n",
        "    return all_characters_in_data\n",
        "    \n",
        "  def get_Sentences_from_Text(self, text):\n",
        "    if type(text)==list:\n",
        "      all_characters_in_data = text\n",
        "    elif type(text) == str:\n",
        "      all_characters_in_data = list(text)\n",
        "    else:\n",
        "      return \"Please pass input either 'List_of_Characters' or 'Text_String'.\"\n",
        "    endChars = self.sentence_EndChars # endChars=\".!?\" ; where '.' -> (period), '!' -> (exclamation mark) and '?' -> (question mark)\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for c in all_characters_in_data:\n",
        "      if c not in endChars:\n",
        "        sentence.append(c)\n",
        "      else:\n",
        "        sentence.append(c)\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    return sentences\n",
        "  \n",
        "  def store_ngrams(self, sentences):\n",
        "    for sent in sentences:\n",
        "      self.train_char_prob = self._char_prob(sent)\n",
        "      ngrams_nextChars = self._get_ngrams(sent)\n",
        "\n",
        "      for ngram_nextChar in ngrams_nextChars: # ((ngram, nextchar), )\n",
        "        self._ngrams_nextChars_List.append(ngram_nextChar)\n",
        "        self._ngrams_List.append(ngram_nextChar[0])\n",
        "        self._ngrams_possChars = self.DF.addVal_to_dictKey(self._ngrams_possChars, ngram_nextChar[0], str(ngram_nextChar[1]))\n",
        "\n",
        "    self.ngrams_nextChars = self.DF.get_dict_from_list(self._ngrams_nextChars_List)\n",
        "    self.ngrams = self.DF.get_dict_from_list(self._ngrams_List)\n",
        "    \n",
        "    # conProb((ngram1, 'c')) = ngrams_nextChars[(ngram1, 'c')]/ngrams[ngram1]\n",
        "    # \"ngrams_nextChars are stored successfully\"\n",
        "\n",
        "    return \"Success: ngrams & ngrams_nextChars are stored successfully\"\n",
        "  \n",
        "  def fit(self, data):\n",
        "    all_characters_in_data = self.clean_data(data)\n",
        "    # sentences = self.get_Sentences_from_Text(all_characters_in_data)\n",
        "    statusMessage = self.store_ngrams([all_characters_in_data])\n",
        "    print(\"==== TRAINING IS COMPLETED ====\")\n",
        "    print(statusMessage)\n",
        "  \n",
        "  def get_prob(self, ngram, char):\n",
        "    if ngram in self.ngrams:\n",
        "      A = self.ngrams[ngram]\n",
        "      self._ngrams_Available.append(ngram)\n",
        "    else:\n",
        "      A = 0\n",
        "      self._ngrams_notAvailable.append(ngram)\n",
        "    \n",
        "    ngram_nextChar = tuple((ngram, char))\n",
        "    if ngram_nextChar in self.ngrams_nextChars:\n",
        "      B = self.ngrams_nextChars[ngram_nextChar]\n",
        "      self._ngrams_nextChars_Available.append(ngram_nextChar)\n",
        "    else:\n",
        "      B = 0\n",
        "      self._ngrams_nextChars_notAvailable.append(ngram_nextChar)\n",
        "    \n",
        "    #if A!=0:\n",
        "    #  result = float(B/A)\n",
        "    #else:\n",
        "    #  result = 0\n",
        "    result = float((B+1)/(A+len(ngram))) # self.train_chars_len\n",
        "    return result\n",
        "  \n",
        "  def evaluate(self, text: str):\n",
        "    text = self.clean_data(text)\n",
        "    self._ngrams_Available = []\n",
        "    self._ngrams_nextChars_Available = []\n",
        "    self._ngrams_notAvailable = []\n",
        "    self._ngrams_nextChars_notAvailable = []\n",
        "    \n",
        "    total_log2loss = 0\n",
        "    ngram = self.n * self.startPad\n",
        "    inputList = list(text)\n",
        "    for char in text:\n",
        "      result = self.get_prob(tuple(ngram), char)\n",
        "      if result != 0:\n",
        "        total_log2loss -= np.log2(result)\n",
        "      \n",
        "      ngram = ngram[1:]+[char]\n",
        "    return total_log2loss/len(inputList)\n",
        "  \n",
        "  def evaluation_Status(self):\n",
        "    print(f\"Not available 'ngrams' are : {'-'*10}\")\n",
        "    print(self._ngrams_notAvailable)\n",
        "    print(f\"Not available 'ngrams_nextChars' are : {'-'*10}\")\n",
        "    print(self._ngrams_nextChars_notAvailable)\n"
      ],
      "metadata": {
        "id": "jKb0_9cofxKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the Datasets**"
      ],
      "metadata": {
        "id": "HvS8ncVwgtFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filePath):\n",
        "  data_cwe = open(filePath, 'r').read().lower()\n",
        "  return data_cwe"
      ],
      "metadata": {
        "id": "rPMI5oACgxwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/drive/MyDrive/NLP/Assignment03/data/cwe-train.txt\"\n",
        "train_data = load_data(filePath)"
      ],
      "metadata": {
        "id": "yi8TCu-bpAMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/drive/MyDrive/NLP/Assignment03/data/cwe-test.txt\"\n",
        "test_data = load_data(filePath)"
      ],
      "metadata": {
        "id": "jEjY7j6zFB8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=15\n",
        "LM_15 = Language_Model(n)\n",
        "LM_15.fit(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbApIzs4SEsl",
        "outputId": "75a7f551-dd64-417d-ddfb-5b28e45780d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== TRAINING IS COMPLETED ====\n",
            "Success: ngrams & ngrams_nextChars are stored successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Log2Loss : {LM_15.evaluate(train_data)}\") \n",
        "\n",
        "print(\"_ngrams_Available : \", len(LM_15._ngrams_Available))\n",
        "print(\"_ngrams_nextChars_Available : \", len(LM_15._ngrams_nextChars_Available))\n",
        "\n",
        "print(\"_ngrams_notAvailable : \", len(LM_15._ngrams_notAvailable))\n",
        "print(\"_ngrams_nextChars_notAvailable : \", len(LM_15._ngrams_nextChars_notAvailable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnzo_SbbTS_a",
        "outputId": "0c5ce560-34b4-42b4-9e81-0c6be7b43900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Log2Loss : 2.7864590801922526\n",
            "_ngrams_Available :  603431\n",
            "_ngrams_nextChars_Available :  603431\n",
            "_ngrams_notAvailable :  0\n",
            "_ngrams_nextChars_notAvailable :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Testing Log2Loss : {LM_15.evaluate(test_data)}\") \n",
        "\n",
        "print(\"_ngrams_Available : \", len(LM_15._ngrams_Available))\n",
        "print(\"_ngrams_nextChars_Available : \", len(LM_15._ngrams_nextChars_Available))\n",
        "\n",
        "print(\"_ngrams_notAvailable : \", len(LM_15._ngrams_notAvailable))\n",
        "print(\"_ngrams_nextChars_notAvailable : \", len(LM_15._ngrams_nextChars_notAvailable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dqg5JqsSdL5",
        "outputId": "1532e18c-7ca4-4cda-fcb7-d5511d80e1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Log2Loss : 3.5794126674101725\n",
            "_ngrams_Available :  15920\n",
            "_ngrams_nextChars_Available :  13311\n",
            "_ngrams_notAvailable :  45796\n",
            "_ngrams_nextChars_notAvailable :  48405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PhNm0pTIPuav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rough**"
      ],
      "metadata": {
        "id": "bqRhOy_6FkYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_Char_List = list(train_data)\n",
        "\n",
        "DF = DictionaryFunctions()\n",
        "train_data_Char_Dict = DF.get_dict_from_list(train_data_Char_List)\n",
        "train_data_Char_Dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWxU1n2RFl2B",
        "outputId": "f8867f6a-29bc-469b-9074-cf77b94bb717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c': 5446,\n",
              " 'h': 20755,\n",
              " 'i': 46266,\n",
              " 'k': 23425,\n",
              " 'a': 87267,\n",
              " 'l': 33255,\n",
              " 'e': 32796,\n",
              " ' ': 84914,\n",
              " 'v': 5778,\n",
              " 'n': 38966,\n",
              " 'o': 26873,\n",
              " 'g': 16766,\n",
              " 'f': 2446,\n",
              " 'y': 17481,\n",
              " 'w': 31352,\n",
              " 'u': 40148,\n",
              " 'b': 7463,\n",
              " \"'\": 2502,\n",
              " 'm': 25905,\n",
              " 's': 10737,\n",
              " ',': 7106,\n",
              " 'j': 1545,\n",
              " 'd': 9800,\n",
              " 't': 7034,\n",
              " '.': 5269,\n",
              " 'p': 1141,\n",
              " 'z': 8054,\n",
              " '\"': 2167,\n",
              " '!': 341,\n",
              " '?': 421,\n",
              " '-': 12,\n",
              " '\\n': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF = DictionaryFunctions()\n",
        "train_data_Char_Prob = DF.find_probs_of_dict(train_data_Char_Dict)\n",
        "train_data_Char_Prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kt2-4uuFl6E",
        "outputId": "7cf8f97d-7917-45e5-ae8e-584ba96d1f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c': 0.009025043418313911,\n",
              " 'h': 0.03439492768033515,\n",
              " 'i': 0.07667143936682178,\n",
              " 'k': 0.0388196184491376,\n",
              " 'a': 0.14461778626257804,\n",
              " 'l': 0.05510977210356759,\n",
              " 'e': 0.0543491230163465,\n",
              " ' ': 0.14071842394834877,\n",
              " 'v': 0.009575229686194965,\n",
              " 'n': 0.06457397022365403,\n",
              " 'o': 0.04453360113484204,\n",
              " 'g': 0.027784406527993213,\n",
              " 'f': 0.004053480756738124,\n",
              " 'y': 0.028969295629002106,\n",
              " 'w': 0.051956144188574686,\n",
              " 'u': 0.0665327659123149,\n",
              " 'b': 0.012367590714446697,\n",
              " \"'\": 0.004146283259754206,\n",
              " 'm': 0.042929443582706915,\n",
              " 's': 0.01779322276577974,\n",
              " ',': 0.011775974757719179,\n",
              " 'j': 0.00256035477071153,\n",
              " 'd': 0.016240438027814236,\n",
              " 't': 0.01165665725384136,\n",
              " '.': 0.00873172122128094,\n",
              " 'p': 0.0018908509989526575,\n",
              " 'z': 0.013346988558777128,\n",
              " '\"': 0.0035911254292115766,\n",
              " '!': 0.0005651009558657811,\n",
              " '?': 0.0006976759601744687,\n",
              " '-': 1.9886250646303147e-05,\n",
              " '\\n': 1.6571875538585954e-06}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for key in train_data_Char_Prob:\n",
        "  sum += train_data_Char_Prob[key]\n",
        "print(sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo18_aRsFl9o",
        "outputId": "026fd9fd-fe93-4f2e-d389-0fc2a3e364fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MoQ6RbfcGxci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_Char_List = list(test_data)\n",
        "\n",
        "DF = DictionaryFunctions()\n",
        "test_data_Char_Dict = DF.get_dict_from_list(test_data_Char_List)\n",
        "test_data_Char_Prob = DF.find_probs_of_dict(test_data_Char_Dict)\n",
        "\n",
        "sum = 0\n",
        "for key in test_data_Char_Prob:\n",
        "  sum += test_data_Char_Prob[key]\n",
        "print(sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shSL_2Y1HFUg",
        "outputId": "d43242c8-2208-47e5-dde4-ac120fb743da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzL1kQWiICME"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}